# -*- coding: utf-8 -*-
"""
Created on Wed May 23 14:22:09 2018

@author: Xiangwei Shi
"""
# This code is based on Pytorch framework.
# The Grad-CAM structure is based on the work of https://github.com/jacobgil/pytorch-grad-cam

# This file is created for generating patches of test images, 
# which are the red and yellow regions in the heatmaps generated by Grad-CAM method.
# And to test the consistancy of heatmaps of the same images generated different models,
# some score is computed for this purpose.

import torch
from torch.autograd import Variable
import torch.nn as nn
import torchvision.models as models
import cv2
import os
import h5py
import numpy as np
import argparse

def preprocess_image(img):
	mean=[0.485, 0.456, 0.406]
	std=[0.229, 0.224, 0.225]
	# opencv imread in BGR order, this code adjust the order of image channel into RGB
	preprocessed_img = img.copy()[: , :, ::-1]
	# image normalization
	for i in range(3):
		preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - mean[i]
		preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / std[i]
	# coverting a numpy Height*Width*nChannels array to nChannels*Height*Width
	preprocessed_img = np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))
	preprocessed_img = torch.from_numpy(preprocessed_img)
	# adding one fake dimension (nTensorSamples*nChannels*Height*Width)
	preprocessed_img.unsqueeze_(0)
	image = Variable(preprocessed_img, requires_grad = True)
	return image

class FeatureExtractor():
    """ Class for extracting activations and 
    registering gradients from targetted intermediate layers """
    def __init__(self, model, target_layers):
        self.model = model
        self.target_layers = target_layers
        self.gradients = []

    def save_gradient(self, grad):
    	self.gradients.append(grad)

    def __call__(self, x):
        outputs = []
        self.gradients = []
        for name, module in self.model._modules.items():
            x = module(x)
            if name in self.target_layers:
                x.register_hook(self.save_gradient)
                outputs += [x]
        return outputs, x

class ModelOutputs():
	""" Class for making a forward pass, and getting:
	1. The network output.
	2. Activations from intermeddiate targetted layers.
	3. Gradients from intermeddiate targetted layers. """
	def __init__(self, model, target_layers):
		self.model = model
		self.feature_extractor = FeatureExtractor(self.model.features, target_layers)

	def get_gradients(self):
		return self.feature_extractor.gradients

	def __call__(self, x):
		target_activations, output  = self.feature_extractor(x)
		output = output.view(output.size(0), -1)
		output = self.model.classifier(output)
		return target_activations, output

class GradCam:
	def __init__(self, model, target_layer_names, use_cuda):
		self.model = model
		self.model.eval()
		self.cuda = use_cuda
		if self.cuda:
			self.model = model.cuda()
		self.extractor = ModelOutputs(self.model, target_layer_names)

	def forward(self, input):
		return self.model(input) 

	def __call__(self, input, index = None):
		if self.cuda:
			features, output = self.extractor(input.cuda())
		else:
			features, output = self.extractor(input)

		if index == None:
			index = np.argmax(output.cpu().data.numpy())

		one_hot = np.zeros((1, output.size()[-1]), dtype = np.float32)
		one_hot[0][index] = 1
		one_hot = Variable(torch.from_numpy(one_hot), requires_grad = True)
		if self.cuda:
			one_hot = torch.sum(one_hot.cuda() * output)
		else:
			one_hot = torch.sum(one_hot * output)

		self.model.features.zero_grad()
		self.model.classifier.zero_grad()
		one_hot.backward(retain_graph=True)

		grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()

		target = features[-1]
		target = target.cpu().data.numpy()[0, :]

		weights = np.mean(grads_val, axis = (2, 3))[0, :]
		cam = np.ones(target.shape[1 : ], dtype = np.float32)

		for i, w in enumerate(weights):
			cam += w * target[i, :, :]

		cam = np.maximum(cam, 0)
		cam = cv2.resize(cam, (224, 224))
		cam = cam - np.min(cam)
		cam = cam / np.max(cam)
		return cam

def generate_heatmap(mask):
	heatmap = cv2.applyColorMap(np.uint8(255*mask), cv2.COLORMAP_JET)
	heatmap = np.float32(heatmap) / 255
	return heatmap

def generate_patch(image, mask, threshold, patch_dir):
	image[mask<=threshold] = 0
	if np.max(image) > 0:
		cam = image / np.max(image)
	else:
		cam = image
	cv2.imwrite(patch_dir + "_patch.jpg", np.uint8(cam*255))

# def average_heatmap(heatmap):
# 	preprocessed_heatmap = heatmap.copy()[:,:,::-1]
# 	preprocessed_heatmap = np.ascontiguousarray(np.transpose(preprocessed_heatmap,(2, 0, 1)))
# 	preprocessed_heatmap = torch.from_numpy(preprocessed_heatmap)
# 	preprocessed_heatmap.unsqueeze_(0)
# 	image = Variable(preprocessed_heatmap)
# 	pool = nn.AvgPool2d(4,4)
# 	average_img = pool(image)
# 	average_img.squeeze_(0)
# 	average_image = average_img.data.numpy()
# 	return average_image

def get_args():
	parser = argparse.ArgumentParser()
	parser.add_argument('--image_folder_path', type=str, help='Input image folder path')
	parser.add_argument('--patch_folder_path', type=str, help='Output patch folder path')
	parser.add_argument('--heatmap_folder_path', type=str, help='Output heatmap folder path')
	args = parser.parse_args()
	return args

if __name__ == '__main__':
	""" 
	1. Loads an image with opencv.
	2. Preprocesses it for trained model that needs visualization and converts to a pytorch variable.
	3. Makes a forward pass to find the category index with the highest score, and computes intermediate activations.
	Makes the visualization. 
	Save the visualization and the most activated regions patch."""
	""" The images that are needed to visualizing are stored in the following structure
	folder-path - class 1
				- class 2
				- ... 
	"""

	args = get_args()
	if torch.cuda.is_available(): # GPU
	    # dtype = torch.cuda.FloatTensor
	    use_gpu = True
	else: # CPU
	    # dtype = torch.FloatTensor
	    use_gpu = False
	device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

	""" The code of Grad-CAM needs 'features' and 'classifier' in the structure of models,
	in order to make it runnable for the models without 'features' and 'classifier', such as Resnet,
	the following class is coded for this purpose"""
	class net(nn.Module):
		def __init__(self):
			super(net,self).__init__()
			self.features = nn.Sequential()
			self.classifier = nn.Sequential()

		def forward(self,x):
			x = self.features(x)
			x = x.view(x.size(0),-1)
			x = self.classifier(x)
			return x

	# Loading the model

	# the first model
	# vgg11 =  models.vgg11()
	# # modifying the number of outputs of vgg11 networks
	# mod = list(vgg11.classifier.children())
	# mod.pop()
	# # In my case, there are only two classes
	# mod.append(torch.nn.Linear(4096,2))
	# new_classifier = nn.Sequential(*mod)
	# vgg11.classifier = new_classifier
	# # vgg11_fr = vgg11
	# vgg11.load_state_dict(torch.load('vgg.pth'))
	# # vgg11_fr.load_state_dict(torch.load('freezed_vgg.pth'))
	# # Copy the model into GPU or CPU
	# vgg11 = vgg11.type(dtype)
	# # vgg11_fr = vgg11_fr.type(dtype)

	# the second model
	# resnet18 = models.resnet18()
	resnet18_2 = models.resnet18()
	# modifying the number of outputs of resnet18 networks
	# resnet18.fc = nn.Linear(512,2)
	resnet18_2.fc = nn.Linear(512,2)
	# resnet18_fr = resnet18
	# resnet18_fr.load_state_dict(torch.load('freezed_resnet.pth'))
	# resnet18.load_state_dict(torch.load('resnet.pth'))
	resnet18_2.load_state_dict(torch.load('Balanced_epoch[13]_learning_rate[0.0000]_resnet_2.pth'))
	# using the class above to add 'features' & 'classifier'
	# my_model = net()
	my_model_2 = net()
	# my_model_fr = net()
	# mod = list(resnet18.children())
	mod_2 = list(resnet18_2.children())
	# mod_fr = list(resnet18_fr.children())
	# layer = mod.pop()
	layer_2 = mod_2.pop()
	# layer_fr = mod_fr.pop()
	# classifier = nn.Sequential(layer)
	classifier_2 = nn.Sequential(layer_2)
	# classifier_fr = nn.Sequential(layer_fr)
	# my_model.classifier = classifier
	my_model_2.classifier = classifier_2
	# my_model_fr.classifier = classifier_fr
	# features = nn.Sequential(*mod)
	features_2 = nn.Sequential(*mod_2)
	# features_fr = nn.Sequential(*mod_fr)
	# my_model.features = features
	my_model_2.features = features_2
	# my_model_fr.features = features_fr
	# Copy the model into GPU or CPU
	# resnet18 = my_model.to(device)
	resnet18_2 = my_model_2.to(device)
	# resnet18_fr = my_model_fr.type(dtype)

	# # simple model
	# class Net(nn.Module):
	#     def __init__(self):
	#         super(Net,self).__init__()
	#         self.features = nn.Sequential(
	#             nn.Conv2d(3,20,5),
	#             nn.ReLU(True),
	#             nn.MaxPool2d(2,2),
	#             nn.Conv2d(20,64,7),
	#             nn.ReLU(True),
	#             nn.MaxPool2d(2,2),
	#             nn.Conv2d(64,96,5),
	#             nn.ReLU(True),
	#             nn.MaxPool2d(2,2),
	#             nn.Conv2d(96,128,7),
	#             nn.ReLU(True),
	#             nn.MaxPool2d(2,2),
	#         )
	#         self.classifier = nn.Sequential(
	#             nn.Linear(128*9*9,4096),
	#             nn.ReLU(True),
	#             nn.Dropout(),
	#             nn.Linear(4096,100),
	#             nn.ReLU(True),
	#             nn.Dropout(),
	#             nn.Linear(100,2),
	#         )
	#     def forward(self,x):
	#         x = self.features(x)
	#         x = x.view(x.size(0),-1)
	#         x = self.classifier(x)
	#         return x

	# simple_model = Net()
	# simple_model.load_state_dict(torch.load('/home/nfs/xiangweishi/Balanced__epoch[27]_learning_rate[0.0000].pth'))
	# simple_model = simple_model.to(device)
	# simple_model.eval()
	# simple_model_2 = Net()
	# simple_model_2.load_state_dict(torch.load('/home/nfs/xiangweishi/Balanced_epoch[27]_learning_rate[0.0000]_simple_2.pth'))
	# simple_model_2 = simple_model_2.to(device)
	# simple_model_2.eval()

	# # simpler model
	# class Simpler(nn.Module):
	#     def __init__(self):
	#         super(Simpler,self).__init__()
	#         self.features = nn.Sequential(
	#             nn.Conv2d(3,20,9),
	#             nn.ReLU(True),
	#             nn.MaxPool2d(2,2),
	#             nn.Conv2d(20,64,9),
	#             nn.ReLU(True),
	#             nn.MaxPool2d(2,2),
	#             nn.Conv2d(64,96,9),
	#             nn.ReLU(True),
	#             nn.MaxPool2d(2,2),
	#         )
	#         self.classifier = nn.Sequential(
	#             nn.Linear(96*21*21,4096),
	#             nn.ReLU(True),
	#             nn.Dropout(),
	#             nn.Linear(4096,100),
	#             nn.ReLU(True),
	#             nn.Dropout(),
	#             nn.Linear(100,2),
	#         )
	#     def forward(self,x):
	#         x = self.features(x)
	#         x = x.view(x.size(0),-1)
	#         x = self.classifier(x)
	#         return x

	# simpler_model = Simpler()
	# simpler_model.load_state_dict(torch.load('/home/nfs/xiangweishi/Balanced__epoch[32]_learning_rate[0.000000]_simpler.pth'))
	# simpler_model = simpler_model.to(device)
	# simpler_model.eval()
	# simpler_model_2 = Simpler()
	# simpler_model_2.load_state_dict(torch.load('/home/nfs/xiangweishi/Balanced_epoch[22]_learning_rate[0.0000]_simpler_2.pth'))
	# simpler_model_2 = simpler_model_2.to(device)
	# simpler_model_2.eval()


	# model = {0:vgg11,1:resnet18,2:vgg11_fr,3:resnet18_fr,4:simple_model}
	# model_name = {0:simple_model,1:simpler_model,2:simple_model_2,3:simpler_model_2}
	model_name = {0:resnet18_2}

	# check point
	print('loading models is done')

	# Generate GradCam class with different pretrained models
	# grad_cam_vgg11 = GradCam(model = vgg11, target_layer_names = ["19"], use_cuda = use_gpu)
	# # grad_cam_vgg11_fr = GradCam(model = vgg11_fr, target_layer_names = ["19"], use_cuda = use_gpu)
	# grad_cam_resnet18 = GradCam(model = resnet18, target_layer_names = ["7"], use_cuda = use_gpu)
	# # grad_cam_resnet18_fr = GradCam(model = resnet18_fr, target_layer_names = ["7"], use_cuda = use_gpu)
	grad_cam_resnet18_2 = GradCam(model=resnet18_2, target_layer_names = ["7"],use_cuda=use_gpu)
	# grad_cam_simple_model = GradCam(model = simple_model, target_layer_names = ["10"], use_cuda = use_gpu)
	# grad_cam_simpler_model = GradCam(model = simpler_model, target_layer_names = ["7"], use_cuda = use_gpu)
	# grad_cam_simple_model_2 = GradCam(model = simple_model_2, target_layer_names = ["10"], use_cuda = use_gpu)
	# grad_cam_simpler_model_2 = GradCam(model = simpler_model_2, target_layer_names = ["7"], use_cuda = use_gpu)
	""" the 'target_layer_names' requires the name of the target convolutional layer that
	needs visualizing after ReLU; in this case, the last convolutional layer is needed to be visualized"""

	# grad_cam = {0:grad_cam_vgg11,1:grad_cam_resnet18,2:grad_cam_vgg11_fr,3:grad_cam_resnet18_fr,4:grad_cam_simple_model}
	# grad_cam = {0:grad_cam_vgg11,1:grad_cam_resnet18,2:grad_cam_simple_model,3:grad_cam_simpler_model}
	# grad_cam = {0:grad_cam_simple_model,1:grad_cam_simpler_model,2:grad_cam_simple_model_2,3:grad_cam_simpler_model_2}
	grad_cam = {0:grad_cam_resnet18_2}

	# check point
	print('generating grad_cams is done')

	# folder_name = {0:'vgg',1:'resnet',2:'vgg_fr',3:'resnet_fr',4:'simple'}
	# folder_name = {0:'vgg',1:'resnet',2:'simple',3:'simpler'}
	# folder_name = {0:'simple',1:'simpler',2:'simple_2',3:'simpler_2'}
	# folder_name = {0:'simpler',1:'simple_2',2:'simpler_2'}
	folder_name = {0:'resnet_2'}
	# threshold = {0:0.5,1:0.6}

	# saving the heatmaps and patches with different models:
	i = -1
	for fold in os.listdir(args.image_folder_path):
		i = i + 1
		folder = os.path.join(args.image_folder_path,fold)
		for image in os.listdir(folder):
			image_dir = os.path.join(folder, image)
			img = cv2.imread(image_dir, 1)
			img = np.float32(cv2.resize(img, (224,224)))/255
			processed_img = preprocess_image(img)
			# threshold = 0.5 # selecting the red and yellow region from the heatmap
			target_index = i
			# If target_index is None, returns the map for the highest scoring category.
			# Otherwise, targets the requested index.
			## compare any two of the models
			for m in range(len(model_name)):
				mask_1 = grad_cam[m](processed_img, target_index)
				heatmap_path = os.path.join(args.heatmap_folder_path,folder_name[m])
				heatmap_dir = os.path.join(heatmap_path,image)
				heatmap_1 = generate_heatmap(mask_1)
				# heatmap_1 = average_heatmap(heatmap_1)
				# img_resize = np.float32(cv2.resize(img, (56,56)))
				# heatmap_1 = np.transpose(heatmap_1,(1,2,0))
				# heatmap_1 = heatmap_1[: , :, ::-1]
				heatmap_cam = heatmap_1 + img
				heatmap_cam = heatmap_cam / np.max(heatmap_cam)
				cv2.imwrite(heatmap_dir + "_heatmap.jpg", np.uint8(heatmap_cam*255))
				# qpatch_path = os.path.join(args.patch_folder_path,folder_name[m])
				# patch_dir = os.path.join(patch_path,image)
	# 			for p in range(len(threshold)):
	# 				if p == 0:
	# 					patch_dir = os.path.join(patch_path,'5')
	# 				else:
	# 					patch_dir = os.path.join(patch_path,'6')
	# 				patch_dir = os.path.join(patch_dir,image)
	# 				generate_patch(img,mask_1,threshold[p],patch_dir)
	# # check point
	# print('patches and heatmaps are all saved')

	# # using h5py file to store score
	# for m in range(len(model_name)):
	# 	for n in range(m+1,len(model_name)):
	# 		i = -1
	# 		residual = []
	# 		for fold in os.listdir(args.image_folder_path):
	# 			folder = os.path.join(args.image_folder_path,fold)
	# 			i = i + 1
	# 			for image in os.listdir(folder):
	# 				image_dir = os.path.join(folder, image)
	# 				img = cv2.imread(image_dir, 1)
	# 				img = np.float32(cv2.resize(img, (224,224)))/255
	# 				processed_img = preprocess_image(img)
	# 				target_index = i
	# 				mask_1 = grad_cam[m](processed_img, target_index)
	# 				heatmap_1 = generate_heatmap(mask_1)
	# 				mask_2 = grad_cam[n](processed_img, target_index)
	# 				heatmap_2 = generate_heatmap(mask_2)
	# 				residual.append(np.sum(np.abs(heatmap_1-heatmap_2))/((224*224*3)))
	# 		f = h5py.File(folder_name[m]+'_'+folder_name[n]+'.h5','w')
	# 		f['data'] = np.asarray(residual)
	# 		f.close()
	# 			# print(m,n)
